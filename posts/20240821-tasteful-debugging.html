<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Tasteful debugging</title>
<link rel="stylesheet" type="text/css" href="../normalize.css" />
<link rel="stylesheet" type="text/css" media="all" href="../styles.css" />
<link rel="stylesheet" type="text/css" media="all" href="../pygments-styles.css" />
<link rel="stylesheet" type="text/css" media="all" href="post-styles.css" />
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>
<body>
  <header><nav><a href="../index.html">Home</a><a href="../posts.html">Posts</a></nav></header>
  <h1>Tasteful debugging</h1><p class="post-date">Wednesday August 21, 2024</p><p>Let‚Äôs put off doing more meaningful work and write down some quick thoughts I have about debugging, since they happen to be on my mind. All of this is just what I feel right now (and is subject to change)! But it‚Äôs also something I feel strongly about and is a big part of what I want to do with my time at the moment.</p><h2>Debugging is useless</h2><p>When you talk about debugging, anyone who‚Äôs written any kind of computer program probably understands what you mean. It‚Äôs likely the most relatable and most inevitable part of software development. Everyone debugs code. Most of software development is, in some sense, debugging.</p><p>Debugging isn‚Äôt really <em>useless</em> (after all, a bug fixed is a bug that can no longer hurt you...right?), but it does depend on what you‚Äôre talking about when you talk about debugging.</p><p>There is an idealized sort of debugging that <em>is</em> actually useful and integral to the software development process. But most real-world debugging is not that. The bug finding and bug fixing process in software, particularly production software, often feels meaningless and pointlessly frustrating.</p><p>The problem isn‚Äôt with the <em>idea</em> of debugging. The problem is that we need to make real-world debugging <em>better</em>.</p><p>The idealized scenario that people often reference when discussing debugging involves a kind of error where there is some <em>essential</em> misunderstanding about the program requirements, about some related system, or about the program itself that needs to be resolved. In these cases, there is something productive happening. You learn something, you get a bit better, perhaps, and the problem is, if you‚Äôve properly understood things, fixed for good<sup><a href="#1_fnref" id="1_fn">(2)</a></sup>.</p><p>This kind of debugging is usually helpful‚Äîit‚Äôs part of the mistake-feedback-learning loop that can make learning programming so fun and interactive. And this kind of debugging <em>is</em> inevitable and integral to the software development process. No one, no matter how excellent, will produce error-free code within an unfamiliar system. There is always a learning curve.</p><p>But most debugging in the real world, in my experience, is not like this. Many misunderstandings that lead to bugs are <em>not</em> about things that are essential, fundamental, or inevitable. Instead, they are results of historical accident. Debugging in real life often either:</p><ul><li>fixes the immediate problem, but results in more bugs and increasing cruft down the line or</li><li>can‚Äôt fully fix the bug because the bug is a result of a misaligned abstraction further down the stack, due to some unprincipled or ad hoc design decision in the system (that might be a bug fix for another, earlier, bug or just an arbitrary, best-guess choice by the system developers).</li></ul><p>Both these things suck. This kind of debugging is stupid and uninteresting. I want my solutions to solve the entire problem, from the bottom up. I want my solutions to last. And I want the source of the bug to be something foundational, something fundamental that I misunderstood. I don‚Äôt want to deal with arbitrary hacks based on unsound, best-effort assumptions.</p><p>But how do we make this all better?</p><aside>There is a blog post by Allison Kaptur titled <a href="https://akaptur.com/blog/2017/11/12/love-your-bugs/" target="_blank" rel="noopener noreferrer">‚ÄúLove Your Bugs‚Äù</a> that I read a while back and that kicked off some thoughts on this general topic. I found the title of the post a little too saccharine (this probably says something about me that might...not be too great). After reading it, I actually did agree with some of what was said, particularly about how bugs can help you learn. That is certainly true, in the ideal (and, I would argue, uncommon) case. I still have issues with the general sentiment of the post‚Äîthat you <em>should</em> love bugs, otherwise you aren‚Äôt going to grow or be a good engineer. Bugs are often incredibly silly, wasteful, and lead to no tangible personal or intellectual growth (except maybe an increasing sense of resignation, which you could spin as ‚Äúpatience‚Äù). We don‚Äôt have to love them. We often should (and could!) try to do better.</aside><h2>A brief note on assumptions</h2><p>There are a number of assumptions in software engineering that I think a lot of practitioners, especially more experienced ones, hold. Some of these assumptions are, to me, a little frustrating. They constrict what people think is possible. They limit what people demand of their tools and their software. It‚Äôs important, at least to me, to not conflate current reality with basic inevitability.</p><div class="callout">Bugs are <em>not</em> a natural, fundamental reality of software.</div><p>One assumption I wish we would abolish is that bugs are some kind of inevitable, natural law of software artifacts. I think the industry is far too accomodating of bugs‚Äîor mistakes, really‚Äîespecially when it is simultaneously trying to push software into more important parts of our lives<sup><a href="#2_fnref" id="2_fn">(3)</a></sup>. Software is, essentially, pure logic. There are no physical realities mandating the presence of bugs. Software by itself can, in theory, be a perfect, perpetual motion machine. That‚Äôs part of its appeal.</p><aside>I saw a comment on HackerNews recently about the terrible mess that the Oracle Database codebase is in‚Äîa codebase that brings to mind a lot of the frustrations I have with debugging (and assumptions!) mentioned above‚Äîand a response that was essentially like, ‚ÄúOMG, what a great piece of engineering! I can‚Äôt believe they can still add features and remain stable and underpin 90% of Fortune 500 companies.‚Äù This is funny to me. I don‚Äôt think this should impress you! This should scare you. This should scare you a lot. You don‚Äôt have to accept your terrible reality<sup><a href="#3_fnref" id="3_fn">(4)</a></sup>...and you certainly don‚Äôt have to celebrate it.</aside><h2>What we (still) lack</h2><p>But we also need to be practical. Humans will, inevitably, make mistakes. What we need are tools, abstractions, and techniques to help us make far fewer mistakes about things that matter‚Äîideally, none at all. In a sense, <em>we need ways to make debugging more pleasant and far more effective.</em></p><p>There are multiple directions from which we can approach this. We should try and <strong>create as few bugs as possible</strong> (during development‚Äîi.e. by-construction), we should try and <strong>surface bugs as quickly as possible</strong> (especially if they make it into production), and we should <strong>make it much easier to fix bugs</strong> when they surface.</p><p>I don‚Äôt think I‚Äôm saying anything radical here, but I do believe that we need far more radical changes to the way we program in order to really accomplish these things in a way that is actually meaningful. We need to push forward both at a developer-facing level (with new products, startups, whatever) and at a deeper, more foundational, research level.</p><p>We need to stop pretending that we already know how best to program and that all we need are some superficial (and possibly LLM-based) tools to help us move faster in paradigms that we‚Äôre already comfortable with. We don‚Äôt need easier ways to make the same mistakes.</p><p>In particular, I believe we need the following:</p><ul><li>better fitting abstractions‚Äîideally, mathematically principled abstractions‚Äîat a systems level, i.e. in the programming languages, databases, file systems, operating systems, etc. that we use (in general, we should aim to solve problems at their essence instead of piling on ad-hoc fixes over the top)</li><li>stronger and broader <em>provable</em> guarantees about important program properties‚Äîprogram proofs should be far more common, starting with the foundational systems we use</li><li>more principled, formal, and automated approaches to testing‚Äîi.e. fuzzing, concolic testing, property-based testing, etc.‚Äîthat are interactive parts of software construction itself (not just something you do when things go wrong in production)</li></ul><p>There are some things being done along these lines in industry that I think are pretty cool. What <a href="https://www.antithesis.com/" target="_blank" rel="noopener noreferrer">Antithesis</a> is doing with deterministic testing (which is an extension of the founders‚Äô previous work on FoundationDB‚Äôs testing system) is awesome and pushes what‚Äôs possible in automated testing and debuggability at scale. I like <a href="https://www.instantdb.com/" target="_blank" rel="noopener noreferrer">InstantDB‚Äôs</a> re-imagining of the database abstraction for client-side collaboration (and also their usage of Clojure!). But we can, and should, go much further. We should try to avoid <a href="https://sourcegraph.com/blog/zig-programming-language-revisiting-design-approach" target="_blank" rel="noopener noreferrer">settling for local maxima</a>.</p><p>I‚Äôm personally very interested in mathematical approaches to these things. I really like the promise of things like program logics and type systems, both intellectually and practically‚Äîbroadly, I think proofs and formal methods are the closest thing to a silver bullet that we have. I find a lot of satisfaction in correctness-by-construction. I like the idea of clean-slate abstractions and fundamental rethinking of our tools.</p><p>This all might sound impractical and overly idealistic, at least in the near-term, but I think this sort of work is leading in very exciting (and practically impactful!) directions, particularly when you take a longer-term view.</p><h2>Fin.</h2><p>One way to sum up is this: debugging is a crucial part of writing software, but it needs to be much more effective. We need a more tasteful debugging experience. Developing simpler, more fitting abstractions at a systemic level, being able to more easily get formal proofs about our software, and surfacing more errors sooner in the development cycle (preferably at the time of construction) are important pieces of making debugging a more productive and useful endeavor.</p><p>Generally, we need far fewer lines of code and far stronger guarantees, particularly about correctness and security, from our software. We‚Äôre simply not going to get that from hacking at things with currently conventional tools.</p><p>Some more food for thought on software quality and verification can be found in Hoare‚Äôs <a href="https://6826.csail.mit.edu/2020/papers/noproof.pdf" target="_blank" rel="noopener noreferrer">‚ÄúHow Did Software Get So Reliable Without Proof?‚Äù</a> and in some of Dijkstra‚Äôs writing and lectures, particularly <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html" target="_blank" rel="noopener noreferrer">‚ÄúThe Humble Programmer.‚Äù</a></p><aside>The Dijkstra lecture mentioned above‚Äî‚ÄúThe Humble Programmer‚Äù‚Äîuses ‚Äúdebugging‚Äù in a different sense than I do here, which lends weight to my point that there‚Äôs no clear and common definition of debugging (making it difficult to discuss properly). I interpret Dijkstra‚Äôs use of ‚Äúdebugging‚Äù to indicate post-facto bug fixing, i.e. fixing bugs in existing systems which have already been deployed in production. I‚Äôve instead used debugging in the general sense of fixing errors in a program. In this sense, even programs that are ostensibly correct-by-construction involve debugging during construction, i.e. figuring out why a machine-checked proof is failing.</aside><p>
</p><section class="footnotes"><ol><li id="0.5_fnref">Having summer break is one the great perks of being in school.<a href="#0.5_fn">‚Ü©</a></li><li id="1_fnref">Even in these cases though, our tools could do more to guide us in correcting these misunderstandings. Ideally, this correction would happen at the time of software construction. At the very least, we need fewer post-hoc, unprincipled fixes to things, something I believe our tools and abstractions can help us with.<a href="#1_fn">‚Ü©</a></li><li id="2_fnref">To be totally fair though, human intent and execution are both fundamentally imperfect. While we should be less accepting of software bugs, we should still always strive to be kind to ourselves (and more generally, the human part of the process)! The answer to all of this is not to punish programmers more for making mistakes. Instead, it's to recognize that our tools should be helping us make fewer mistakes and to demand more of the software artifacts we produce and use.<a href="#2_fn">‚Ü©</a></li><li id="3_fnref">OK, maybe this is a little too strident. Sometimes you do need to accept your reality, no matter how terrible, if you want to remain sane. But I do stand by my point that you don't need to celebrate it. That just feels like blatant Stockholm syndrome.<a href="#3_fn">‚Ü©</a></li><li id="3.1_fnref">For reference, take any inference rule style presentation of Andersen's algorithm, which should be accessible with a quick web search or LLM query üôÉ<a href="#3.1_fn">‚Ü©</a></li><li id="4_fnref">Since BFS is technically linear time, for example, or more specifically $\mathcal{O}(V+E)$ for some graph $G = (V, E)$. Or an appeal to Wikipedia citations <a href="https://en.wikipedia.org/wiki/Reachability#cite_note-4" target="_blank" rel="noopener noreferrer">here</a>.<a href="#4_fn">‚Ü©</a></li><li id="1.5_fnref">In all fairness, this is probably true of most jobs. But I do feel like there is something particularly soul-draining about corporate software jobs.<a href="#1.5_fn">‚Ü©</a></li><li id="5_fnref">But I don't know. Here's a bit of a rant. <em>Some opinions, beliefs, and values are just fundamentally misaligned.</em> And I don't necessarily think Recurse is entirely immune to that fact. There's a reason I'm choosing to leave the software industry, at least for now. I'm tired of the endless cycles of hype-chasing and profit-seeking, the maddening rat race ("Why doesn't your 5-year-old know how to code!!" or "I did 1000 LeetCode questions and you must too!!!"), the corporate brand worship ("I'm an ex-FAANG early hire at Notion please fund my AI startup"), the latent arrogance in Silicon Valley culture, and so on. No, your startup is probably not going to disrupt, or "innovate," or change the world in any way that actually matters. It's time that we all stop pretending we know how to program effectively (and all we need are some LLMs or a better JS framework to make things easier) or that software has a good answer to all of our problems. Providing real value to the world is often not correlated to profitability. You don't have to major in computer science. It's going to be OK.<a href="#5_fn">‚Ü©</a></li></ol></section><footer>‚ô¶‚ô¶‚ô¶</footer></body>
</html>