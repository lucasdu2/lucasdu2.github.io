<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>AWS, Cloudflare, and centralization</title>
<link rel="stylesheet" type="text/css" href="../normalize.css" />
<link rel="stylesheet" type="text/css" media="all" href="../styles.css" />
<link rel="stylesheet" type="text/css" media="all" href="../pygments-styles.css" />
<link rel="stylesheet" type="text/css" media="all" href="post-styles.css" />
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>
<body>
  <header><nav><a href="../index.html">Home</a><a href="../posts.html">Posts</a></nav></header>
  <h1>AWS, Cloudflare, and centralization</h1><p class="post-date">Wednesday December 24, 2025</p><p>Somewhat recently, both <a href="https://www.theregister.com/2025/10/23/amazon_outage_postmortem/" target="_blank" rel="noopener noreferrer">AWS</a> and <a href="https://www.theregister.com/2025/11/18/cloudflare_outage/" target="_blank" rel="noopener noreferrer">Cloudflare</a> experienced major outages: these had some pretty widespread impacts on real humans (and also on corporate bottom lines). Also, just over a year ago, <a href="https://en.wikipedia.org/wiki/2024_CrowdStrike-related_IT_outages" target="_blank" rel="noopener noreferrer">CrowdStrike</a> caused another massive global outage that negatively affected <a href="https://www.wired.com/story/crowdstrike-outage-update-windows/" target="_blank" rel="noopener noreferrer">lots of different industries</a>, i.e. air travel, finance, and healthcare.</p><p>Everyone relies on software these days! (More or less. Or at least increasingly so.) Events like these, which make very clear just how dependent we are on brittle, complicated, and unreliable software is...a bit disturbing, to say the least.</p><aside>To make matters much worse, these kinds of outages are just the visible tip of the iceberg. Many software errors and oversights manifest not as open and obvious crashes, but as security vulnerabilities. (Unintended privacy leaks<sup><a href="#0_fnref" id="0_fn">(1)</a></sup> are another concern!) For example, take the recent critical security vulnerability in React: <a href="https://www.cve.org/CVERecord?id=CVE-2025-55182" target="_blank" rel="noopener noreferrer">CVE-2025-55182</a> (React2Shell), which exploits an error in HTTP deserialization to achieve remote code execution.<sup><a href="#1_fnref" id="1_fn">(2)</a></sup></aside><p>I think there are a couple real ways forward, and I’ll try to relatively quickly sketch them out. It’s probably worth prefacing this with my deep distaste for the common refrain that <em>we just need better bureaucratic processes or developer protocols</em> within the companies producing software.</p><p>I don’t think that this sort of perspective—which generally results in more administrative overhead, red tape, and an AI/LLM savior complex<sup><a href="#2_fnref" id="2_fn">(3)</a></sup>—actually gets us anywhere meaningfully better: it only offers bandaids for much deeper problems. Top-down policy that relies heavily on human input, coordination, and diligence doesn’t really scale; AI and LLM-based attempts to scale this kind of heuristic administrative oversight only serves to delay a more painful (but more essential) reckoning. What we need, I argue, is <em>structural change</em> at the level of <em>programming tools, abstractions, and infrastructure</em>.</p><h3>A brief qualification</h3><p>None of this is to say that human factors are unimportant! There are lots of cases where human factors are deeply important, but I think only insofar that those factors <em>shape</em> and <em>are shaped</em> by the structural tools, abstractions, and infrastructure we develop around them.</p><p>For example, take supply chain attacks, which seem to be inevitable in a world where (a) software projects often have large dependency graphs and (b) few, if any, software packages or modules come with formal security guarantees. Supply chain attacks (and other, related kinds of coordinated attacks on social networks, e.g. <a href="https://en.wikipedia.org/wiki/Google_bombing" target="_blank" rel="noopener noreferrer">Google bombing</a> or <a href="https://en.wikipedia.org/wiki/Sybil_attack" target="_blank" rel="noopener noreferrer">Sybil attacks</a>) abuse and exploit notions of <em>trust</em>, which inherently (I think) cannot be strictly and precisely quantifiable—these notions must involve human factors!</p><p>The best we can do is develop formal models of trust, and then develop structural tools, abstractions, and infrastructure—whether it’s public key infrastructure, PGP keys and the “web of trust,” Byzantine fault tolerant consensus protocols, decentralized and distributed ledgers, and so on—to help us (a) trust fewer things and (b) make more explicit <em>what</em> we’re trusting.</p><aside>For what it’s worth, trust in computer science sort of feels like a never-ending black hole, and it makes me feel weird. See the classic <a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf" target="_blank" rel="noopener noreferrer">“Reflections on Trusting Trust”</a> lecture by Ken Thompson. I want provable, verifiable guarantees, and notions of “trustworthiness” just don’t often fit that bill. (Also of interest here is <a href="https://dwheeler.com/trusting-trust/" target="_blank" rel="noopener noreferrer">David A. Wheeler’s Diverse Double Compiling (DDC) counter</a> to the sort of attack described by Thompson.)</aside><h2>Software centralization and lack of end-user control</h2><p>One major concern that I have with all of these recent outages is that it exposes just how centralized the internet really is. In brief: I think the internet (and software in general) should be far more <strong>decentralized</strong> and <strong>local-first</strong>. None of this is particularly revolutionary, given all the recent activity around things like open <a href="https://en.wikipedia.org/wiki/Mastodon_(social_network)" target="_blank" rel="noopener noreferrer">social</a> <a href="https://en.wikipedia.org/wiki/Bluesky" target="_blank" rel="noopener noreferrer">networks</a> (<a href="https://en.wikipedia.org/wiki/Matrix_(protocol)" target="_blank" rel="noopener noreferrer">and</a> <a href="https://en.wikipedia.org/wiki/ActivityPub" target="_blank" rel="noopener noreferrer">associated</a> <a href="https://en.wikipedia.org/wiki/AT_Protocol" target="_blank" rel="noopener noreferrer">protocols</a>) and <a href="https://martin.kleppmann.com/papers/local-first.pdf" target="_blank" rel="noopener noreferrer">local-first software</a>.</p><p>I think work in these directions is all very timely and important. Should we all be (unwittingly) relying on Amazon AWS to store and access much of our online data? Should we be collaborating online and sharing information primarily through Google Drive’s suite of applications? Should our <a href="https://arstechnica.com/gadgets/2025/10/smart-beds-leave-sleepers-hot-and-bothered-during-aws-outage/" target="_blank" rel="noopener noreferrer">mattresses</a> be connected to the internet? Should a remote software update from a single entity <a href="https://timesofindia.indiatimes.com/world/us/hospitals-from-new-york-to-london-paris-struggle-in-tech-outage/articleshow/111867131.cms" target="_blank" rel="noopener noreferrer">deny healthcare providers access to local patient data</a>? Should we be relying, for the most part, exclusively on Github (which is now <a href="https://arstechnica.com/gadgets/2025/08/github-will-be-folded-into-microsoft-proper-as-ceo-steps-down/" target="_blank" rel="noopener noreferrer">owned by Microsoft</a>) to store, access, and work on open-source code?</p><p>I don’t think so. This state of affairs feels increasingly untenable: it harms and disempowers users, frustrates software developers, and seems only to serve an increasingly wealthy and politically powerful technocratic ruling class. Consumer-facing software should not require internet access to function, users should own their data, and computing infrastructure must diversify, decentralize, and perhaps even <a href="https://sandersinstitute.org/technofeudalism-explained-with-yanis-varoufakis" target="_blank" rel="noopener noreferrer">socialize</a> (although I am less convinced of the latter).</p><p>That being said, this is all rather idealistic: there are clear challenges in practice, particularly regarding <em>decentralization</em>. There are good reasons (e.g. convenience, user experience, short-term and small-scale cost effectiveness) why large centralized platforms and infrastructure providers (i.e. the “cloud”) have become hugely popular.</p><p>I don’t want to get too in the weeds here, so I’ll just link to some articles and posts that I find interesting in this regard:</p><ul><li>A back-and-forth about federation vs. decentralization in the context of Bluesky vs. Mastodon, between Christine Lemmer-Webber<sup><a href="#3_fnref" id="3_fn">(4)</a></sup> and Bryan Newbold: <a href="https://dustycloud.org/blog/how-decentralized-is-bluesky/" target="_blank" rel="noopener noreferrer">“How decentralized is Bluesky really?”</a>; <a href="https://whtwnd.com/bnewbold.net/3lbvbtqrg5t2t" target="_blank" rel="noopener noreferrer">“Reply on Bluesky and Decentralization”</a>; and <a href="https://dustycloud.org/blog/re-re-bluesky-decentralization/" target="_blank" rel="noopener noreferrer">“Re: Re: Bluesky and Decentralization”</a></li><li>Critiques of Matrix, an open and federated messaging protocol: <a href="https://forum.hackliberty.org/t/why-we-abandoned-matrix-the-dark-truth-about-user-security-and-safety/224" target="_blank" rel="noopener noreferrer">“Why We Abandoned Matrix”</a>; and <a href="https://signal.org/blog/the-ecosystem-is-moving/" target="_blank" rel="noopener noreferrer">“Reflections: The ecosystem is moving”</a> (by one of the founders of Signal, critiquing federated platforms and protocols)</li><li>“Finished,” long-lasting software: <a href="https://rosswintle.uk/2025/10/software-can-be-finished/" target="_blank" rel="noopener noreferrer">“Software can be finished”</a> (by Ross Wintle); <a href="https://world.hey.com/dhh/finished-software-8ee43637" target="_blank" rel="noopener noreferrer">“Finished software”</a> (by David Heinemeier Hansson); and <a href="https://jeffhuang.com/designed_to_last/" target="_blank" rel="noopener noreferrer">“This Page is Designed to Last”</a></li></ul><aside>The last bullet point above isn’t directly related to decentralization, but I think ideas of enduring, self-contained, local-first software (that doesn’t need constant updates or continuous connection to centralized servers, that users can fix themselves, and that work even when the company that made it no longer exists) are similar in spirit, or at least offer a similar path forward. Far too much software requires an internet connection nowadays to even function–or to not go wrong in some essential way—and I think that is generally bad. Software should work out of the box. Internet connectivity should only be required if it is necessary for some core functionality.</aside><h2>Abstraction (and tooling) support</h2><p>The core of my stance on these outages (and, more broadly, on the state of modern software) is this: we need <em>better support from our programming tools and abstractions</em>, both to make more decentralization more practical, and to prevent the bugs that caused these centralized outages from happening in the first place. I’m primarily interested in approaches centered around <em>programming languages</em> (fairly broadly construed), and <em>formal methods</em>.<sup><a href="#4_fnref" id="4_fn">(5)</a></sup></p><h3>Distributed systems are hard</h3><p>I think this is, by now, a fairly uncontroversial point. Making distributed systems work correctly and reliably is an immensely difficult task, even for hugely profitable software firms—like Amazon and Google—whose profits depend on these systems working correctly and reliably. There are two complementary responses to this observation:</p><ul><li>Perhaps most immediately, I think lots of software that doesn’t need to be distributed should not be distributed. At the very least, limit the distribution and keep things as simple as possible, as long as possible. Some other (more reputable, perhaps) people have also championed this view recently: some of my favorites are <a href="https://youtu.be/Ps3AI1kTIR4?si=_Qs6ewNsoIL-09_g" target="_blank" rel="noopener noreferrer">this video</a> on YouTube (“AWS is 10x slower than a dedicated server for the same price”) and <a href="https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf" target="_blank" rel="noopener noreferrer">this excellent paper</a> (“Scalability! But at what COST?”).</li><li>It should also be easier to build correct, reliable distributed systems. I think this really comes down to better abstraction design: are there <em>simpler</em> models within which programmers can express their intentions in a distributed way, and are there ways to let formally and mechanically check our work on these distributed systems (perhaps by leveraging computers themselves) to give us solid, provable guarantees?</li></ul><p>I think programming languages research has a lot of very fruitful things to say about abstraction design for distributed systems (and abstraction design in general).<sup><a href="#6_fnref" id="6_fn">(6)</a></sup> And I think formal verification—trying to get provable guarantees about global properties of computing systems—should play a much larger role in the software development process, partcularly for foundational and complicated distributed systems. Of course, there is a good deal of research work that still needs to be done to make this more widely practical. Case in point: Amazon (AWS) runs <a href="https://www.amazon.science/research-areas/automated-reasoning" target="_blank" rel="noopener noreferrer">a large programming languages/formal verification</a> research group (probably the largest currently in industry).</p><h3>It should be far easier to “roll your own” infrastructure</h3><p>A big reason why people (and companies) reach instinctively for managed, cloud-based services is that it’s just <em>easy</em>. I think there is a really interesting, and pretty practical/industry-facing area of work in making locally-managed, fully-owned, and low-dependency compute infrastructure easier and more usable. This really isn’t an area that I think really demands any interesting research advances to make possible<sup><a href="#7_fnref" id="7_fn">(7)</a></sup>: we have all the tools we need! It’s simply a matter of the right player(s) coming in and developing better end-to-end tooling, making the user experience palatable, and getting some industry traction. There are already some startups in this space, i.e. <a href="https://oxide.computer/" target="_blank" rel="noopener noreferrer">Oxide</a>.</p><h3>It should be far easier to write local-first software</h3><p>Similarly, a big reason why developers often develop in a cloud-oriented way is that it is also just easier. Cloud-based services have lots of industry mindshare, a good deal of developer goodwill, and a cottage industry of developer tooling and related services that make the service fairly painless, at least at the beginning. This is fair, but not optimal. Lots of software should not be developed in a cloud-first way. I believe that better tooling and better user experience for building local-first software can help a lot in this regard. And again, there is already a good deal of practical, industry-oriented work in this space, i.e. <a href="https://github.com/automerge/automerge" target="_blank" rel="noopener noreferrer">Automerge</a>, <a href="https://www.inkandswitch.com/local-first-software/" target="_blank" rel="noopener noreferrer">Ink and Switch’s work</a> (although this is a bit more research-y), and the <a href="https://lofi.so/directory" target="_blank" rel="noopener noreferrer">local-first development community</a>.</p><h3>How about testing?</h3><p>In all honesty, I don’t really believe that “better testing” (i.e. the current crop of LLM-driven testing tools, simply “spending more time in staging environments,” or even property-based/fuzz testing—which I am admittedly rather interested in) will move the needle meaningfully forward or get us to where I believe we should want to be. I’ve already written a bit about this in <a href="https://lucaszdu.com/posts/20240821-tasteful-debugging.html" target="_blank" rel="noopener noreferrer">a previous post.</a></p><p>My main gripes with a testing-centric approach are basically:</p><ul><li>The actual <em>design</em> of a system often makes the system <em>hard to test</em> effectively—the solution in this case <em>should</em> be to design the system in a better way, but testing offers little guidance on how to do this. In fact, I would argue that many modern systems are convoluted enough that they <em>cannot</em> be tested effectively. Similarly, they also cannot be debugged effectively, although this relates more to the second point below.<sup><a href="#5_fnref" id="5_fn">(8)</a></sup></li><li>The classic refrain is that testing can prove the existence of bugs, but not the absence. Proving the existence of bugs is actually very helpful and effective (I’m certainly not anti-testing by any means—testing is important!), but once testing has found a bug, it often doesn’t offer clear guidance on how to fix the bug (particularly: how to fix the bug without introducing more bugs).</li><li>The state space of possible errors, particularly in concurrent and distributed software, is enormous. While intelligent testing campaigns can try to search “interesting” parts of this space, and deterministic testing frameworks can help in reproducing the bugs that are found, I think this is still deeply unsatisfying and almost always only finds what I would consider to be low-hanging fruit. We can and should look for more certainty, by developing programming abstractions and models that <em>restrict</em> this state space and provide <em>constructive guarantees</em> about what cannot go wrong. Testing, programming language design, and formal verification can (and should) go hand-in-hand!</li></ul><h2>Looking forward, looking back</h2><p>I think that what these outages point to is actually a fairly desperate need for <em>better programming abstractions</em>, from first principles. Software programs, particularly distributed systems, are increasingly foundational parts of society as a whole, and I believe we need better ways to build and reason about them, not only for commercial reasons, but also for social reasons. The answer isn’t LLM-based tools<sup><a href="#8_fnref" id="8_fn">(9)</a></sup> that help us build <em>vastly more</em> software in the same ways; we need to build <em>vastly better</em> software, in <em>better</em> ways.</p><p>There are a couple quotes from <a href="https://www.computerworld.com/article/4082890/the-aws-outage-post-mortem-is-more-revealing-in-what-it-doesnt-say.html" target="_blank" rel="noopener noreferrer">an article in ComputerWorld</a> about the AWS outage that I really liked, and I’ll end with them.</p><p>From Chris Ciabarra, the CTO of Athena Security:</p><aside>“Amazon is admitting that one of its automation tools took down part of its own network. The outage exposed how deeply interdependent and fragile our systems have become. It doesn’t provide any confidence that it won’t happen again. ‘Improved safeguards’ and ‘better change management’ sound like procedural fixes, but they’re not proof of architectural resilience. If AWS wants to win back enterprise confidence, it needs to show hard evidence that one regional incident can’t cascade across its global network again. Right now, customers still carry most of that risk themselves.”</aside><p>And from Catalin Voicu, an engineer at N2W Software:</p><aside>“The underlying architecture and network dependencies still remain the same and will not go away unless there is an entire re-architect of AWS. AWS claims a 99.5% availability for this reason. They can put band aids on problems,  but the nature of these hyperscalers is that core services call back to specific regions. This is not going to change anytime soon.”</aside><p>This where programming languages and formal methods research is actually very practically useful, and not just an intellectual curiosity (as some would like to claim)! It can help guide the development and design of simpler, more efficient, and more provably reliable distributed systems, in ways that aren’t just band aids over intractable problems rooted in historical accident and backwards compatibility requirements.<sup><a href="#9_fnref" id="9_fn">(10)</a></sup></p><section class="footnotes"><ol><li id="0_fnref">Privacy, more broadly construed, <a href="https://www.ted.com/talks/glenn_greenwald_why_privacy_matters" target="_blank" rel="noopener noreferrer">also</a> <a href="https://www.goodreads.com/en/book/show/55332285-why-privacy-matters" target="_blank" rel="noopener noreferrer">matters</a>! (At least I think so.) But regardless, <em>unintended leaks</em> of privacy are certainly a bad thing.<a href="#0_fn">↩</a></li><li id="1_fnref">We really should formally verify parsers and de/serializers. And people are trying to do that! (And have been for some time.) See, for example: <a href="https://www.andrew.cmu.edu/user/bparno/papers/vest.pdf" target="_blank" rel="noopener noreferrer">Vest</a> (MSR, Northeastern, UMD, CMU), <a href="https://www.galois.com/project/daedalus" target="_blank" rel="noopener noreferrer">Daedalus</a> (Galois). Or some more foundational theoretical work, which I really don't understand (but seems quite interesting): <a href="https://dl.acm.org/doi/10.1145/3729281" target="_blank" rel="noopener noreferrer">"Intrinsic Verification of Parsers and Formal Grammar Theory in Dependent Lambek Calculus"</a> from PLDI 2025.<a href="#1_fn">↩</a></li><li id="2_fnref">This is a bit tongue in cheek! But there's a broader opinion I have here about LLMs and their impact in the software industry that I don't really want to totally unpack right now. The gist is that I believe much of the perceived and actual usefulness of LLMs in industry software development stems from the (unnecessary, but immediately profitable) acceptance of enormous complexity as natural and inevitable. What else to do then, but pray at the altar of a massive, incomprehensible, computationally overwhelming god to save us from this inhumanity! While I do think there is useful work being done (and to be done!) in this direction, it's not really what I believe in or want to spend time on.<a href="#2_fn">↩</a></li><li id="3_fnref">Christine Lemmer-Webber also does lots of <a href="https://spritely.institute/" target="_blank" rel="noopener noreferrer">very cool work</a> on decentralized infrastructure! (With Scheme no less, which is even cooler.)<a href="#3_fn">↩</a></li><li id="4_fnref">Perhaps it's obvious by now what kind of computer science research I find most compelling...<a href="#4_fn">↩</a></li><li id="6_fnref">I'm certainly not the first or only person to notice this. See recent-ish work by Heather Miller, Mae Milano, Lindsey Kuper, etc. on language designs for distributed systems, and see lots of work every year at programming languages and formal verification conferences on these kinds of topics, i.e. verification techniques for concurrent/distributed systems and weak-memory models. For what it's worth, this is probably the body of work that first got me interested in programming languages as a research field and one that continues to really interest me.<a href="#6_fn">↩</a></li><li id="7_fnref">Although there is actually really interesting work in terms of better languages for declarative infrastructure, for example, or even language/OS co-design for better distributed systems administration! I think these are actually cool research directions, but they aren't required to make "roll your own" infrastructure possible.<a href="#7_fn">↩</a></li><li id="5_fnref">This relates a bit to why I like programming languages: I think a language-oriented approach---and often a <em>functional</em> and <em>type-based</em> approach---actually shapes software design in a way that <em>aids</em> testability and debuggability, and allows more complete and effective (formal) reasoning about software, at least at the logical level. There is something to be said about functional languages requiring more complicated compilers and such, but I actually don't personally view this as a big issue, particularly as someone who believes that foundational software infrastructure like compilers should be increasingly formally verified anyway. There are also interesting and important (in my opinion) research problems in highly efficient compilation of functional languages.<a href="#5_fn">↩</a></li><li id="8_fnref">Perhaps it's more nuanced to say that the answer isn't <em>just</em> LLM-based tools: clearly, LLMs are useful for many software tasks. But I do think that the push for AI/LLMs in software development and the amount of funding in this direction is too much. There are more foundational problems that need to be addressed, and AI/LLMs are just very fancy band-aids. But I'm obviously biased.<a href="#8_fn">↩</a></li><li id="9_fnref">Another related and very interesting article on this is <a href="https://www.shadaj.me/writing/distributed-programming-stalled" target="_blank" rel="noopener noreferrer">"Distributed Programming Has Stalled"</a> by Shadaj Laddad.<a href="#9_fn">↩</a></li></ol></section><footer>Questions? Comments? Corrections? Email me at lzdu ∊ ucdavis [dot] edu!</footer></body>
</html>